________________________________________
# LCB - レイヤード座標ビットストリーム
日本語としては複層座標ビットストリーム

## 概要
LCB は、多分野のセンサーおよび意味情報を標準化・圧縮するための汎用 AI データレイヤーです。言語、セキュリティ、医療、自動運転、測定などさまざまな分野で、軽量かつ説明可能、拡張性の高い AI 処理を可能にします。

## 特徴
- **レイヤー構造:** 空間座標、属性、変化ベクトル、メタタグ、信頼度。
- **ビットストリーム化:** 高圧縮・NPUやエッジデバイス向けに最適化。
- **時系列ベクトル:** RNN / LSTM を使わず高速推論が可能。
- **拡張可能:** 新しいセンサーや属性の追加もモデル再学習不要。
- **プライバシー配慮:** 生画像や音声の送信不要。座標＋ビットのみで対応。
- **Human-in-loop:** 信頼度に応じて不確実な場合に警告可能。

## 応用分野
- 言語: 音声、テキスト、感情検知。
- セキュリティ・医療: 群衆監視、患者トラッキング。
- 自動運転: 車両・歩行者検出、リスク予測。
- 測定・分析: 建物劣化、植物成長、環境監視。

## ライセンス / 公開方針
- オープンでの利用を推奨。
- コードおよび仕様は著作権で保護。貢献歓迎。

作者はITやAIの技術者ではないため、AIの助けを借りて作成しています。現在のディープランニング一辺倒によるAI処理に対しLCBの利用はディープラーニング処理を補完し、より効率的に確実に計算を行うことができるようになると思われます。
学習データと辞書構造の分離の可能性があること、構造の分離の可能性がある。辞書データ自体はAIにより辞書データ自体は原理上、学習なしにより作成可能です。もっとも、辞書データ作成AIのモデル自体は必要です。


 
LCB仕様書 ver0.3（公開検討用バージョン）
※本仕様書はドラフトです。作者はIT技術者でないために。考えることはできても、実装できませんので、AIの助けを借りて作成しております。皆様の意見等をいただきながら。修正していけると良いと考えております。

________________________________________
✅ 多層インタラクションエンコーディング仕様書 — Version 0.3（日本語版）
________________________________________
0. 概要
本仕様書は、人間–機械インタラクションを効率的かつ拡張性をもって表現するための、階層化されたデータ構造（フレーム形式）を定義する。
対象範囲は、UI/AR/VR/ロボティクス/音声対話/テキスト対話/センサー入力など、広汎な入力システムである。
本仕様は以下を提供する：
•	決定的で再構築可能なバイナリ構造
•	version付き辞書参照（差分更新可能）
•	感情ベクトル＋拡張ブロック
•	座標スケールの標準化
•	座標浮動小数（float16）オプション
•	時系列変化（Δ）
•	テンプレート参照とシーケンス情報
これは多用途かつ将来拡張可能なデータ交換標準の候補として設計されている。
________________________________________
1. データモデルの層構造
1つの「インタラクションフレーム」は以下の8層から構成される。
layer_mask で存在する層のみを送信できる。
L0 – 空間・位置情報
L1 – 入力モダリティ種別
L2 – 意味情報（辞書参照）
L3 – 感情ベクトル
L4 – 時系列変化（Δベクトル）
L5 – 環境情報（予約）
L6 – エージェント状態（予約）
L7 – テンプレート参照 & シーケンス
________________________________________
2. バイナリフレーム構造
バイト	フィールド	説明
0	version	8bit。現在は 0x03 を使用
1	layer_mask	16bit。各層の有無を示すフラグ
2以降	層のデータ	maskに従って順番に格納
________________________________________
2.1 Layer Mask の割り当て
ビット	層	使用状況	備考
0	L0	✅	空間情報
1	L1	✅	入力モダリティ
2	L2	✅	辞書参照
3	L3	✅	感情
4	L4	✅	Δベクトル
5	L5	✅（予約）	環境、視覚属性
6	L6	✅（予約）	ジェスチャー等
7	L7	✅	テンプレート
8–15	—	🚫予約	将来の拡張領域
________________________________________
3. 各層（Layer）詳細
________________________________________
3.1 L0 空間情報（座標）
ジェスチャー中心、ポインタ、センサー値、AR空間アンカーなどの位置情報を扱う。
形式：
coord_type     8bit  (0=int16、1=float16)
coord_scale    8bit  (0=1cm, 1=0.1cm, 2=1mm, 3=100m, 4=緯度経度モード)
x              16bitまたはfloat16
y              同上
z              同上
座標スケール=4 の場合 → 緯度経度モードで float16 として扱う。
________________________________________
3.2 L1 入力モダリティ
modality_type: 8bit  
0 = テキスト  
1 = 音声  
2 = ポインタ  
3 = ジェスチャー  
4 = センサー  
5 = コマンド  
6 = システムイベント  
________________________________________
3.3 L2 意味情報（辞書参照形式）
辞書参照は世界共通形式を採用。
dict_id       32bit  (<lang><domain><major><minor>)
dict_version   8bit
token_id       16bit
dict_id の構造：
バイト	内容
0	言語コード（ISO-639-1の簡易コード）
1	ドメイン（0=一般、1=UI、2=ロボット等）
2	メジャークラス（大分類）
3	マイナークラス（細分類）
衝突回避ガイドライン：
•	メジャークラスは開発者固有領域として予約可能
•	マイナークラスは内部階層化に使用
________________________________________
3.4 L3 感情ベクトル
基本5軸 + 拡張ブロックを採用。
基本軸（各8bit）：
joy（喜）
anger（怒）
sadness（哀）
fear（怖）
neutral（中立）
拡張ブロック
count        8bit
values[]     各8bit
例：驚き、皮肉、安堵など文化依存の表現に対応。
________________________________________
3.5 L4 時系列変化（Δ）
感情・位置の変化を表現する。
dx 16bit signed
dy 16bit signed
dz 16bit signed
d_emotion_count 8bit
d_emotion_values[] 各8bit
________________________________________
3.6 L5 環境レイヤー（予約）
将来案：
•	環境雑音
•	照度
•	近接オブジェクト
•	温度
________________________________________
3.7 L6 エージェント状態（予約）
将来案：
•	ジェスチャースケルトン
•	視線方向
•	注意度
•	AI内部推定（信頼度等）
________________________________________
3.8 L7 テンプレート参照
テンプレート文や音声プロンプト、シーンデータの参照。
template_id       32bit
template_version   8bit
reference_type     8bit  (0=ローカル、1=URL、2=埋め込み)
sequence_index     16bit
________________________________________
4. 辞書管理（同期・更新）
4.1 差分更新方式
辞書アップデートは以下の形式で送信：
patch_type     8bit   (0=追加, 1=削除, 2=更新)
dict_id        32bit
dict_version   8bit
payload_length 16bit
payload[]      任意形式
メリット：
•	軽量
•	バージョン同期
•	差分適応が容易
________________________________________
5. Merkle圧縮プロトコル
フレーム数が増えた場合にブロック化してハッシュ化。
256フレーム単位でMerkleノード生成  
ノード = SHA256(個々のフレームのハッシュ)
検証：
クライアント→root受領  
サーバ→特定フレームへの証明を提示  
________________________________________
6. バイナリ例（概念）
version: 0x03
layer_mask: 0b000010111
L0: (coord_type=0, coord_scale=1, x=123, y=455, z=20)
L1: modality=pointer
L2: dict_id=0x01.02.15.03, version=4, token=32
L3: joy=200, anger=0, sadness=10, fear=30, neutral=15
L4: dx=0, dy=-3, dz=0
L7: template_id=0x00000010, version=1, seq_index=12
________________________________________
7. 実装要件
本仕様を公開する際は最低1つの実装を含める。
•	Pythonによるエンコード/デコード例
•	C構造体の例（推奨）
•	テンプレート再生用の簡易デモアプリ
________________________________________
8. 国際化（I18N）について
•	言語コードは ISO-639-1 ベース
•	文字コード処理は辞書側に委譲
•	UTF-8データは直接格納しない（id参照方式）
________________________________________


2025年11月10日　加藤今北事務所　


 
________________________________________
資料①：辞書作成手順（LCB-Lang 用）
________________________________________
✅ ① 辞書作成手順（Dictionary Construction Workflow）— Version 0.3
________________________________________
1. 概要
本資料は、多層インタラクションエンコーディング仕様書（ver0.3）における 辞書（Dictionary）構造の作成手順 を定義する。
辞書は語彙情報を階層化ID（dict_id）として表現し、言語・ドメイン・分類情報を持つ。
また差分更新（version管理）を前提としている。
________________________________________
2. 辞書の全体構造
辞書は以下の3階層の情報を持つ：
1.	メタ情報（header）
2.	辞書エントリ（entry）
3.	バージョン差分（patch）
________________________________________
2.1 メタ情報（header）
項目	内容
dict_language	ISO-639-1準拠（例：ja, en, ko）
dict_domain	分野（一般、UI、ロボティクス、医療など）
dict_major	大分類
dict_minor	細分類
dict_version	8bit整数
________________________________________
2.2 辞書エントリ（entry）
各エントリは以下の属性を持つ：
属性名	型	説明
token_id	uint16	辞書内の語彙のユニークID
surface	UTF-8	表記（word）
reading	UTF-8	読み（音声入力等）
pos	uint8	品詞情報
semantic	uint16	意味カテゴリー
flags	uint8	特殊処理フラグ（固有名詞/専門語/禁止語など）
________________________________________
3. 辞書ID（dict_id）構成規則
<lang><domain><major><minor>
各1バイト（8bit）で合計32bit。
________________________________________
3.1 lang（言語コード）
lang	言語
0x01	日本語
0x02	英語
0x03	韓国語
0x04	中国語
________________________________________
3.2 domain（ドメインコード例）
domain	分野
0x00	一般
0x01	UI操作
0x02	ロボティクス
0x03	車載（自動運転）
0x04	医療
0x05	工学（制御/IoT）
________________________________________
3.3 major / minor（分類）
例：ロボティクス分野
major	カテゴリ
0x10	移動
0x11	関節動作
0x12	把持・物体操作
0x13	センサー認識
minor（例）
minor	小分類
0x01	前進
0x02	後退
0x03	右旋回
0x04	左旋回
________________________________________
4. 辞書作成のワークフロー
________________________________________
4.1 Step 1：辞書の目的を定義する
以下を明確にする：
•	対応言語
•	対応ドメイン
•	想定アプリケーション
•	必要語彙集合（最大語彙数）
________________________________________
4.2 Step 2：語彙ソースの収集
語彙は複数のソースから得る：
•	コーパス抽出（自然言語）
•	UIログ（GUI操作）
•	ロボットコマンド仕様書
•	車載HMI（自動運転）
•	医療マニュアル
________________________________________
4.3 Step 3：品詞・カテゴリー分類
語彙を分類する：
属性	説明
pos	名詞、動詞、形容詞、助詞など
semantic	意味概念（距離、速度、方向、安全性）
flags	固有名詞/危険語彙/特殊処理語
________________________________________
________________________________________
4.4 Step 4：token_id の割り当て
token_id = 16bit（最大 65,536 語彙）
ルール：
1.	0〜255：予約（システム用）
2.	256〜：一般語彙
3.	安全・警告語彙は10000番台
4.	専門語彙は20000番台
________________________________________
4.5 Step 5：辞書の物理ファイル生成
推奨フォーマット（JSON）
{
  "header": {
    "lang": 1,
    "domain": 3,
    "major": 16,
    "minor": 1,
    "version": 2
  },
  "entries": [
    {
      "token_id": 256,
      "surface": "前進",
      "reading": "ぜんしん",
      "pos": 1,
      "semantic": 101,
      "flags": 0
    },
    ...
  ]
}
________________________________________
4.6 Step 6：辞書チェック
以下を自動検査：
•	token_id 重複
•	UTF-8エンコード確認
•	pos の正当性
•	semanticの競合
•	versionの整合性
________________________________________
4.7 Step 7：辞書パッチ（差分更新）の生成
変更がある場合：
{
  "patch_type": 0,
  "dict_id": 0x01_03_10_01,
  "dict_version": 3,
  "payload": {
     "added": [
       { ... }
     ]
  }
}
________________________________________
4.8 Step 8：共有・同期
配布方法：
•	GitHub rawファイル
•	HTTPS API
•	CDN配布
•	アプリ内部キャッシュ
________________________________________
5. 品質管理
自動テスト項目
テスト	説明
hash整合性	辞書全体のSHA256
辞書のサイズ	最大2MB推奨
冗長性チェック	似た語彙の重複排除
________________________________________

 
________________________________________
資料②：単語ID／辞書ID割り当て

________________________________________
② 単語ID／辞書ID 割り当て規則（LCB v0.3）
1. 基本方針
1.	一意性確保
o	同じ単語（表記・発音・意味）には常に同じIDを割り当てる。
2.	階層構造の明示
o	言語／分野／メジャー／マイナー／バージョン
3.	拡張性
o	新語・方言・技術語などを容易に追加可能。
4.	軽量・整数ベース
o	バイト単位で管理し、検索・圧縮・差分更新が容易。
________________________________________
2. 単語ID（Word ID）の構造
フィールド	バイト数	内容	備考
lang_id	1B	言語種	例：0=日本語、1=英語、2=中国語 …
domain_id	1B	分野/ジャンル	例：0=一般語、1=科学、2=文学 …
major_id	2B	主語彙分類	大分類でグループ化
minor_id	2B	サブ分類	サブカテゴリ、同音異義語対応
version	1B	単語バージョン	更新・修正管理用
合計	7B	単語ID	100万語規模まで余裕
特徴
•	言語ごとに重複を避けつつ、分野別に整理可能。
•	versionフィールドで辞書更新・同期が容易。
•	minor_id で派生語・同音異義語・方言などを区別。
________________________________________
3. 辞書ID（Dictionary ID）の構造
辞書IDは「辞書自体を一意に識別するコード」。
単語IDとは別に管理。
フィールド	バイト数	内容	備考
dict_lang	1B	言語種	単語IDのlang_idと対応
dict_domain	1B	分野/ジャンル	単語IDのdomain_idと対応
dict_version	1B	バージョン	差分更新・互換管理
dict_type	1B	種類	例：0=基本、1=拡張、2=方言、3=専門用語
合計	4B	辞書ID	軽量でURL/ファイル管理に適する
________________________________________
4. 階層構造のイメージ
[言語] (lang_id)
 └─ [分野/ジャンル] (domain_id)
      └─ [メジャー分類] (major_id)
           └─ [サブ分類] (minor_id)
                └─ [単語バージョン] (version)
•	単語IDの7Bで、階層的に参照可能。
•	辞書IDと組み合わせて、辞書の同期や更新が容易。
________________________________________
5. 単語IDの生成規則
1.	新語登録時
o	言語/分野/大分類/小分類を決定
o	version = 0 で初期登録
o	自動でユニークIDを割り振り
2.	辞書更新時
o	修正語は version +1
o	minor_id は変更なし
3.	差分更新
o	dict_version と word version の組み合わせで差分パッチ生成
4.	同義語・方言
o	minor_id で区別
o	発音・意味が同一なら major_id同一、minor_id別
5.	削除・廃止
o	削除フラグは辞書管理ファイルに記録
________________________________________
6. 運用上の注意点
•	単語ID/辞書IDは 整数・バイト配列で保持
→ 検索・圧縮・差分更新が容易
•	辞書同期時は version + dict_version で整合性チェック
→ 差分パッチ生成で通信負荷を最小化
•	新規言語追加は lang_id 空きを確保して拡張可能
•	辞書種別 (dict_type) を明確化することで、特定分野のみの読み込み・圧縮が可能
________________________________________
7. 例
単語ID例（日本語・科学・化学・元素）
lang_id = 0 (日本語)
domain_id = 1 (科学)
major_id = 0x0010 (化学)
minor_id = 0x0005 (水素)
version = 0x01
→ WordID = 0x00 01 00 10 00 05 01
辞書ID例（日本語・科学基本辞書 v1）
dict_lang = 0
dict_domain = 1
dict_version = 0x01
dict_type = 0 (基本辞書)
→ DictionaryID = 0x00 01 01 00
________________________________________
8. 今後の拡張案
•	URL/ローカル併用
→ dict_type + dict_version でクラウド/ローカル混在管理
•	国際対応
→ lang_id拡張で多言語辞書管理
•	時間軸付き単語
→ versionに時間情報を統合し、古語・現代語対応
•	暗号署名
→ 将来的に辞書IDに署名追加で改ざん検知可能
________________________________________

 
資料③：単語ID／辞書ID管理運用フロー
________________________________________
③ 単語ID／辞書ID管理運用フロー（LCB v0.3）
1. 基本方針
1.	安全な一意性の維持
o	単語IDは辞書内で重複しないよう管理。
o	辞書IDは辞書ファイル単位で唯一。
2.	差分管理で更新を効率化
o	バージョン管理により、更新・追加・削除を差分パッチで伝達。
3.	階層参照で柔軟性
o	言語／分野／分類単位で管理・検索可能。
4.	オフライン対応
o	ローカルPCでも単語検索・更新可能。
________________________________________
2. 運用フロー概要
[単語登録] → [辞書更新] → [差分生成] → [配布／同期] → [削除/廃止]
フローの各段階
________________________________________
2-1. 単語登録
1.	新規単語の入力
o	表記／発音／意味／属性を決定。
o	発音座標（CPCS）、意味座標（SCS）、拡張属性、文単位SCFも同時登録。
2.	階層割り当て
o	lang_id / domain_id / major_id / minor_id を決定。
3.	Word ID生成
o	version = 0
o	自動で7B配列として生成。
4.	辞書ファイルへの追加
o	該当辞書IDに対応するJSON/バイナリファイルに追記。
5.	確認・検証
o	ID重複チェック
o	CRCやチェックサムで整合性確認
________________________________________
2-2. 辞書更新
1.	単語情報の修正
o	意味変更、発音修正、属性追加など。
2.	Word version更新
o	version += 1
3.	辞書IDは同一
o	dict_version は辞書全体更新時にのみ更新。
4.	履歴管理
o	差分更新・古いバージョン保持により、ロールバック可能。
________________________________________
2-3. 差分生成・同期
1.	対象単語抽出
o	Word version > 配布済み version
2.	差分パッチ作成
o	変更単語ID＋更新内容のみ
o	圧縮形式：JSON / バイナリ差分
3.	署名・検証
o	オプション：ECDSA署名で改ざん検知
4.	配布
o	クラウドURL or ローカル配布
5.	受信側適用
o	単語IDをキーに上書き／追加
o	versionチェックで古い単語はスキップ
________________________________________
2-4. 単語削除／廃止
1.	削除フラグ設定
o	Word IDに deleted: true を付加
2.	差分パッチ配布
o	他のシステムは同IDを参照時にスキップ
3.	物理削除（任意）
o	古いバージョンをバックアップ後、辞書から削除
4.	履歴管理
o	削除理由・日付をメタデータとして保持
________________________________________
3. フローチャート（簡易）
+----------------+      +------------------+      +----------------+
| 新規単語登録   | ---> | 辞書更新         | ---> | 差分生成/同期   |
+----------------+      +------------------+      +----------------+
        |                       |                         |
        v                       v                         v
  ID生成・整合性          version更新               署名/圧縮
        |                       |                         |
        +-----------------------+-------------------------+
                                |
                                v
                        単語削除/廃止
________________________________________
4. 運用上の留意点
項目	留意点
ID重複	自動チェック機能必須
version	Word version と dict_version の整合性確認
同期	差分パッチは必ず単語IDベースで管理
多言語	lang_id 拡張で追加言語対応
差分の適用順序	古いversion → 新しいversion の順序で適用
セキュリティ	署名・CRCで改ざん防止
________________________________________
5. 例
新規単語追加
単語: 「酸素」
発音座標(CPCS): X=50, Y=100, Z=0
意味座標(SCS): θ=10, r=50, z=0
拡張属性: 感情=中立, 外来語=0
文単位SCF: 発話者1, ネスト0, 時間=現在, 空間=室内

WordID = 0x00 01 00 10 00 06 00
辞書ID = 0x00 01 01 00
version = 0
単語更新（意味変更）
WordID = 0x00 01 00 10 00 06 00
version = 1
変更内容: 意味座標 r=55, z=5
差分パッチ作成 → 同期適用
削除
WordID = 0x00 01 00 10 00 06 00
deleted = true
差分パッチ適用 → 他端末で参照不可
________________________________________
 
資料④：言語・音声の前処理手順

________________________________________
④ 言語・音声の前処理手順（LCB v0.3）
1. 目的
•	単語ID／辞書IDに基づいた軽量言語モデルへの入力準備
•	音声・文字情報を統一フォーマットに変換
•	文脈・属性情報を付与して解析・検索効率化
________________________________________
2. 前処理フロー概要
[テキスト/音声入力] → [正規化] → [分割] → [音声座標変換] → [意味座標変換] → [文脈属性付与] → [単語ID割当]
________________________________________
3. 各段階の詳細
3-1. テキスト正規化
処理内容	方法/例	備考
全角→半角変換	「ＡＢＣ」→「ABC」	一貫した文字コード管理
大文字→小文字変換	「Apple」→「apple」	英語圏対応
記号削除	「!@#」→空白	辞書未対応文字は削除 or 置換
数字統一	「２」→「2」	文脈に応じて丸数字も変換
不要空白削除	「Hello World」→「Hello World」	文単位分割の精度向上
________________________________________
3-2. 文節／単語分割
処理内容	方法	備考
日本語形態素解析	MeCab / Sudachi	語単位でID割当
英語分割	空白・句読点	併用で単語境界検出
句読点保持	「, . ?」	文脈属性SCF付与のため
________________________________________
3-3. 発音座標変換（CPCS）
処理内容	方法	出力例
音素分解	IPA変換 or 辞書参照	/a/, /k/, /s/
座標化	X=子音群、Y=母音パターン、Z=音長・アクセント	X=50, Y=100, Z=0
正規化	0–255整数	バイト格納可能
※ 外来語・方言は辞書ベースで補正
________________________________________
3-4. 意味座標変換（SCS）
処理内容	方法	出力例
分野・ジャンル判定	単語・文脈解析	θ=10
専門度判定	語彙レベル・文書類型	r=50
文体・公共性判定	フォーマル／カジュアル／スラング	z=0
拡張属性付与	感情／季節／外来語／方言	emotion=中立, foreign=0
________________________________________
3-5. 文脈属性付与（SCF）
項目	ビット数	例	備考
発話者ID	6	0–63	話者識別
発話種別	2	自発/応答/中立/案内	文の役割
ネスト深度	3	0–7	引用や入れ子文
時間軸	4	過去/現在/未来/仮定	文脈管理
空間軸	6	室内/屋外/仮想＋方向	位置・方向情報
トピックID	8	0–255	話題分類
拡張予約	3	予備	将来拡張用
文頭にSCFを付与することで、文脈管理や引用・ネスト文処理が容易になる
________________________________________
3-6. 単語ID割当
処理内容	方法	出力例
辞書検索	正規化済み単語 + CPCS/SCS参照	WordID=0x00 01 00 10 00 06 00
未登録単語	新規ID生成	version=0
差分管理	既存単語の更新・削除	version+=1, deleted=true
________________________________________
4. フロー図（簡易）
[テキスト/音声入力]
        |
        v
  [正規化・分割]
        |
        v
[発音座標変換 CPCS] ---> [意味座標変換 SCS]
        |                        |
        +----------> [文脈属性付与 SCF] ----> [単語ID割当]
________________________________________
5. 留意点
項目	留意点
外来語	発音辞書を参照、未登録は暫定座標
方言	CPCS補正ルールで座標化
音声長短	Z軸で符号化、正規化後格納
文脈依存	SCFの付与順序に注意（入れ子文・引用文）
差分更新	既存単語の更新は version に基づき反映
________________________________________
6. 実用例
入力例
テキスト: 「明日は雨が降るかもしれない。」
前処理結果（抜粋）
単語	CPCS(X,Y,Z)	SCS(θ,r,z)	SCF
明日	X=50,Y=100,Z=0	θ=10,r=50,z=0	発話者1, 時間=未来
は	X=0,Y=0,Z=0	θ=0,r=0,z=0	SCF同上
雨	X=30,Y=120,Z=0	θ=12,r=40,z=0	SCF同上
が	X=0,Y=0,Z=0	θ=0,r=0,z=0	SCF同上
降る	X=60,Y=110,Z=5	θ=10,r=55,z=0	SCF同上
かも	X=20,Y=80,Z=0	θ=0,r=50,z=0	SCF同上
しれ	X=20,Y=80,Z=0	θ=0,r=50,z=0	SCF同上
ない	X=0,Y=0,Z=0	θ=0,r=0,z=0	SCF同上
この出力により、単語ID付与・検索・距離計算が即座に可能。
________________________________________

 
資料⑤：デモアプリケーションコード例
________________________________________
1. 目的
•	単語ID／辞書IDに基づき、テキスト入力から発音・意味・文脈属性を付与
•	軽量検索・補正・変換のデモを Python で実装
•	フロー理解および実装マニュアルの参考
________________________________________
2. 前提データ構造
# CPCS: 発音座標
class CPCS:
    def __init__(self, x=0, y=0, z=0):
        self.x = x
        self.y = y
        self.z = z

# SCS: 意味座標
class SCS:
    def __init__(self, theta=0, r=0, z=0, emotion=0):
        self.theta = theta
        self.r = r
        self.z = z
        self.emotion = emotion

# SCF: 文脈属性（32bit）
class SCF:
    def __init__(self, speaker=0, type=0, nest=0, time=0, space=0, topic=0):
        self.speaker = speaker
        self.type = type
        self.nest = nest
        self.time = time
        self.space = space
        self.topic = topic

# 単語構造
class WordEntry:
    def __init__(self, text, cpcs, scs, scf, word_id=0):
        self.text = text
        self.cpcs = cpcs
        self.scs = scs
        self.scf = scf
        self.word_id = word_id
________________________________________
3. サンプル辞書（軽量版）
# 仮辞書（WordID: 0x0001〜）
dictionary = {
    "明日": WordEntry("明日", CPCS(50,100,0), SCS(10,50,0,0), SCF(1,0,0,1,0,0), 0x0001),
    "雨": WordEntry("雨", CPCS(30,120,0), SCS(12,40,0,0), SCF(1,0,0,1,0,0), 0x0002),
    "降る": WordEntry("降る", CPCS(60,110,5), SCS(10,55,0,0), SCF(1,0,0,1,0,0), 0x0003),
}
________________________________________
4. 距離計算関数
def euclidean_distance(c1, c2):
    return ((c1.x-c2.x)**2 + (c1.y-c2.y)**2 + (c1.z-c2.z)**2) ** 0.5

def semantic_distance(s1, s2):
    d_theta = min(abs(s1.theta - s2.theta), 256 - abs(s1.theta - s2.theta))
    d_r = abs(s1.r - s2.r)
    d_z = abs(s1.z - s2.z)
    return (d_theta + d_r + d_z)/3

def total_distance(w1, w2, w_phon=0.6, w_sem=0.4):
    return w_phon*euclidean_distance(w1.cpcs, w2.cpcs) + w_sem*semantic_distance(w1.scs, w2.scs)
________________________________________
5. デモ変換関数
def correct_word(input_word):
    if input_word in dictionary:
        return dictionary[input_word]
    # 未登録語: 仮ID生成
    return WordEntry(input_word, CPCS(), SCS(), SCF(), word_id=0xFFFF)
________________________________________
6. サンプル処理：文単位
sentence = ["明日", "は", "雨", "が", "降る"]
processed = []

for word in sentence:
    entry = correct_word(word)
    processed.append(entry)

# 結果表示
for e in processed:
    print(f"Word: {e.text}, ID: {hex(e.word_id)}, CPCS:({e.cpcs.x},{e.cpcs.y},{e.cpcs.z}), "
          f"SCS:({e.scs.theta},{e.scs.r},{e.scs.z}), SCF speaker:{e.scf.speaker}")
出力例（抜粋）
Word: 明日, ID: 0x1, CPCS:(50,100,0), SCS:(10,50,0), SCF speaker:1
Word: は, ID: 0xffff, CPCS:(0,0,0), SCS:(0,0,0), SCF speaker:0
Word: 雨, ID: 0x2, CPCS:(30,120,0), SCS:(12,40,0), SCF speaker:1
________________________________________
7. 検索・補正デモ
# 入力単語: 「あめ」
input_word = "あめ"
# 類似語探索
distances = [(w.text, total_distance(WordEntry(input_word, CPCS(30,120,0), SCS(12,40,0), SCF(1,0,0,1,0,0)), w))
             for w in dictionary.values()]
distances.sort(key=lambda x: x[1])
print("候補:", distances[:3])
説明
•	CPCS/SCSの座標距離で候補提示
•	類似発音・意味の語を上位表示
•	SCFにより文脈に合わせた補正も可能
________________________________________
8. 留意点・拡張
項目	説明
外来語	仮CPCS座標を自動生成
文脈補正	SCF情報を活用して語順や意味を考慮
辞書更新	WordIDに基づき差分反映可能
GUI統合	TkinterやPyQtで補正UI構築可能
________________________________________
9. まとめ
•	このデモコードは LCB v0.3 のフローを一通り体験できる
•	発音座標（CPCS）、意味座標（SCS）、文脈属性（SCF）、単語ID管理が統合されている
•	軽量でオフライン動作可能
•	実際の製品では辞書を拡張し、文脈ベクトルや属性をより精密に設定可能
________________________________________
 
________________________________________
 
意味座標系の詳細仕様（第1版）
1. 基本構造
•	名称：意味座標系（lcb-space）
•	構成：3軸
o	r軸（関係性）
o	z軸（属性性）
o	s軸（文脈強度・位相）
•	単位：各軸16ビット構成（0〜65535）、4〜15ビットを主評価領域
•	型：ビット列＋ラベル構造。数値距離およびカテゴリ的整合性を同時に扱う
________________________________________
2. 軸別定義
2.1 r軸（関係性：Relational）
•	意味内容：他概念との結合傾向、抽象度、概念ネットワーク上の位置
•	上位構造例：
o	具体的関係（行為・対象・主体など）
o	機能的関係（目的・作用・影響）
o	抽象的関係（因果・条件・包含など）
•	小分類例：
o	4〜7ビット：主関係カテゴリ（主体↔客体、原因↔結果）
o	8〜11ビット：関係の方向性（能動／受動、前提／帰結）
o	12〜15ビット：関係の強度・持続・多重性
2.2 z軸（属性性：Attributive）
•	意味内容：性質・状態・価値などの静的特徴
•	上位構造例：
o	物理的属性（形状・質感・温度など）
o	機能的属性（能力・速度・安定性など）
o	評価的属性（良否・美醜・価値判断）
•	小分類例：
o	4〜7ビット：属性カテゴリ（物理／心理／社会）
o	8〜11ビット：属性の方向（＋／−、強／弱）
o	12〜15ビット：主観度・社会的共有度
2.3 s軸（文脈強度・位相：Situation）
•	意味内容：文脈内での顕現度、感情的強度、適用範囲
•	小分類例：
o	4〜7ビット：時間的位相（過去／現在／未来）
o	8〜11ビット：感情強度（静／動）
o	12〜15ビット：場面依存性（一般／特定）
________________________________________
3. ビット構造の扱い
•	下位4ビット（0〜3）：同義語や細分類識別子（語派や方言、言語差）
•	主評価領域（4〜15ビット）：各軸の意味的重心。計算・評価対象
•	上位ビット（16）：軸全体の有効フラグ（1=有効, 0=無効）。欠測データ対応
________________________________________
4. 意味空間の階層構造
•	上位：概念領域（存在／関係／属性）
•	中位：カテゴリー群（物理的・心理的・社会的）
•	下位：意味素（semantic unit）＝各軸の4〜15ビットで定義
•	構造間リンク：
o	is-a（上位下位）
o	part-of（全体部分）
o	affect（影響関係）
o	contrast（対義・反転）
________________________________________
5. 計算・評価の基本原理
•	意味距離：
D = √( w_r (r1-r2)² + w_z (z1-z2)² + w_s (s1-s2)² )
•	意味相関：cos類似度またはHamming距離を使用可能
•	分類単位：ビット群をクラスタリングし、共通意味空間を定義（クラスタラベルをカテゴリ辞書として付与）
________________________________________
6. 拡張予定
•	感情空間との統合（valence-arousalとの対応）
•	多言語対応（同一概念の言語座標マッピング）
•	機械学習での逆推定（文脈から座標推定）
________________________________________
7. 次段階：単語拡張評価のための調査・手法設計
7.1 目的
1.	各単語のr軸・z軸の4〜15ビットがどの情報源から定まるか
2.	自動・半自動的に評価・拡張するための指標・評価法を確立
7.2 主要検討項目
区分	調査・評価対象	手法候補
r軸	概念ネットワーク（WordNet, ConceptNet, 大規模コーパス共起）	グラフ中心性・クラスタ分析
z軸	感性語・形容詞ベクトル・心理尺度	感情値・PCA主成分分析
s軸	文脈出現頻度・感情極性・対話強度	時系列分析・BERT類似空間投影
全体	ビットパターン抽出と検証	教師データ（辞書／人手ラベル）＋機械学習補正
________________________________________
意味座標系（lcb-space）ビット構造および分類図表
【表1】全体構成概要
軸名	機能区分	意味内容	主評価ビット（4〜15）	備考
r軸（Relational）	関係性	概念間の関係・結合・方向性・抽象度	12bit	主体↔客体・因果・前提関係などを表す
z軸（Attributive）	属性性	性質・状態・価値・社会的性格など	12bit	公共度・文化属性・省略性などを含む
s軸（Situational）	文脈性	文脈上の位相、感情的強度、場面依存性	12bit	感情・時制・場面的強度などを表す
共通構造	16bit／軸	下位4bit=識別／主評価12bit／上位フラグ1bit		0〜3bitは方言・細分類、16bitは有効フラグ
________________________________________
【表2】r軸（関係性）ビット構造詳細
ビット範囲	名称	内容	値例	補足
0〜3	下位分類ID	方言・派生語識別	例：0001=方言A	概念差異の識別用
4〜7	主関係カテゴリ	主体・客体・原因・結果	例：0000=主体、1111=結果	因果・方向性の主軸
8〜11	関係方向性	能動／受動、前提／帰結	例：0101=能動	意味の動的傾向を示す
12〜15	強度・持続・多重性	関係の強さ・期間・重層性	例：1000=強、1111=恒常	連続関係を数値化
16	軸フラグ	有効=1／無効=0	1	欠測時制御用
________________________________________
【表3】z軸（属性性）ビット構造詳細
ビット範囲	名称	内容	値例	補足
0〜3	下位分類ID	言語差・方言識別	例：0001=英語派生	
4〜7	属性カテゴリ	物理・心理・社会属性	0000=物理, 0111=心理	
8〜11	属性方向	正負、強弱、安定・不安定	0100=正／強	評価的属性に関与
12〜15	公共度レベル	俗語〜国際語	0000=俗語, 1111=国際語	WordNet検証軸にも対応
16	軸フラグ	有効=1／無効=0	1	
________________________________________
【表4】s軸（文脈強度・位相）ビット構造詳細
ビット範囲	名称	内容	値例	補足
0〜3	下位分類ID	方言・用法差	-	
4〜7	時間的位相	過去／現在／未来	例：0000=過去, 1111=未来	
8〜11	感情強度	静／動／高揚／沈静	例：0100=静, 1110=高揚	
12〜15	場面依存性	一般／特定／儀礼的	例：0011=特定	
16	軸フラグ	有効=1／無効=0	1	
________________________________________
【表5】θ軸（分野大分類・小分類）構造案（参考）
角度	大分類（上位カテゴリ）	小分類例（4bit）	対義方向（180°）	備考
0°	数学・論理	数・構造・証明・推論	哲学・思想（180°）	抽象始点
22.5°	修辞学・言語学	構文・音韻・語彙・文体	文学	表現構造領域
45°	情報・計算機	アルゴリズム・情報構造・通信・AI	芸術・表現	工学的思考と創造性の対
67.5°	物理学・力学	運動・エネルギー・波動・量子	教育・学習	法則と実践
90°	工学・技術	機械・電子・材料・建築	社会科学・経済	構築と分析
112.5°	化学・生化学	元素・反応・有機・物質	法律・行政	反応と規範
135°	医学・健康	解剖・生理・薬理・心理	宗教・哲学	治療と救済
157.5°	哲学・思想	形而上・倫理・存在・論理	数学・論理	抽象終点
180°	言語学	言語構造・意味論・音声・語用	修辞学	
202.5°	文学	物語・詩・劇・評論	論理学	
225°	芸術・表現	音楽・絵画・舞台・デザイン	情報・計算機	
247.5°	教育・学習	学習法・教育理論・訓練・指導	物理学・力学	
270°	社会科学・経済	経済・社会・心理・政策	工学・技術	
292.5°	法律・行政	法体系・手続・制度・行政	化学・生化学	
315°	宗教・哲学	信仰・儀礼・倫理・救済	医学・健康	
337.5°	日常・生活	実用・習慣・民俗・文化	数学・論理（0°）	抽象との連続点
________________________________________
【表6】z軸 公共度レベル16段階（例）
値	名称	内容例
0	俗語	ネットスラング、方言
1	口語	日常会話レベル
2	準口語	軽い敬語、話し言葉文体
3	標準語	一般文体
4	準公式語	文書・報道・説明書など
5	公式語	行政・法令用語
6	専門語	技術・学術用語
7	学術語	学会・論文レベル
8	国際語（技術）	ISO・国際規格等
9	国際語（文化）	UNESCO等国際共通文化語
10〜15	拡張予約	将来拡張・AI共通語
________________________________________
【表7】r軸 専門性レベル（例）
値	概要	対応層
0	一般人	日常語彙
1	学習者	学校教育語彙
2	準専門家	実務知識層
3	専門家	業界・研究者
4	研究者	論文レベル
5	指導層	専門教育者
6〜15	予約領域	高次専門概念・抽象化語
________________________________________
【図解イメージ（説明用）】
            ↑ z軸：属性性（公共・文化・省略）
            │
            │
            │
            │
←────────┼────────→ r軸：関係性（抽象⇔具象）
            │
            │
            │
            ↓
          s軸：文脈強度（位相・感情）
 
________________________________________
意味座標系（lcb-space）座標算出アルゴリズムおよびビット評価仕様
________________________________________
【表1】座標算出の基本方針
項目	内容	補足
座標算出対象	各単語または語群（句・節）	単語単位で基本座標を算出し、文レベルでは加重平均または系列折れ線化
入力データ	意味素（WordNet等の上位下位関係）＋統計情報（頻度・共起）＋人文指標	WordNetは検証用、最終は独立語彙体系を想定
出力データ	(θ, r, z) の三軸＋文脈補正（Δr, Δz, Δθ）	各軸16bit評価値を正規化して0〜1範囲に射影
処理段階	①基礎割当 → ②補完補正 → ③連結ベクトル化 → ④グラフ描画	折れ線グラフは各文の「意味軌跡」になる
補完方式	低ビット欠損時は上位軸の平均値補完／近傍語補正	欠損を容認し、系列の滑らかさを優先
対応空間	円筒座標空間（θ, r, z）	θ=分野角度、r=専門性・関係強度、z=公共・文化高低
________________________________________
【表2】ビット評価の基準（r軸）
ビット範囲	意味区分	評価基準	数値化方法	補足
4〜7	主体・客体関係	文中の係り受け・主述関係	主体=0.2〜0.4、客体=0.6〜0.8	NLP構文解析で判定可能
8〜11	能動・受動方向	動詞態（active/passive）や依頼表現	能動=+、受動=−	構文解析＋依存木方向
12〜15	専門性	頻度逆数・技術語リスト参照	score = log(1/freq) を正規化	用語コーパスから推定
0〜3	下位ID	方言・派生形	辞書タグ参照	必要に応じ自動付与
________________________________________
【表3】ビット評価の基準（z軸）
ビット範囲	意味区分	評価基準	数値化方法	補足
12〜15	公共度	国語辞典・報道頻度・SNS頻度	正規化頻度＋文体分類	「俗語」〜「国際語」間の16段階スケール
8〜11	属性方向	ポジティブ／ネガティブ／安定／不安定	感情極性＋確信度	Word2Vec/感情辞書対応
4〜7	属性カテゴリ	物理／心理／社会	共起語のクラスタ解析	共起ベクトルから分野推定
0〜3	下位分類	方言・派生	簡易タグ	任意
________________________________________
【表4】ビット評価の基準（θ軸：角度変換）
項目	内容	算出式	備考
大分類角度	16区分（0〜15）×22.5°	θ = index × 22.5°	表5参照
小分類角度補正	各大分類内で±5°以内補正	θ' = θ + (sub / 16 × 10° - 5°)	小分類ビット0〜15に対応
平滑化補正	文中の連続単語に対して平均化	θ_final = mean(θ_i)	折れ線変化の急激化を抑制
対義反転処理	対向分野ではπ（180°）シフト	θ_antonym = θ + π	意味の対立を空間的に表現
________________________________________
【表5】文脈補正係数（Δr, Δz, Δθ）
要素	補正対象	基準値	評価基準	効果
感情強度	Δz	±0.05〜0.2	ポジ／ネガスコア	感情が強いほど高さ変動
論理接続	Δr	±0.1	and／but／if構造	抽象度補正
否定語	Δθ	+π（反転）	not／never／without等	ベクトル反転による意味転換
比喩・皮肉	Δr, Δz	変動比率20〜40%	比喩判定スコア	意味反転＋強調補正
終止／疑問	Δz	±0.05	文末終助詞	発話の高さ調整
________________________________________
【表6】算出アルゴリズム（擬似コード）
for word in sentence:
    θ = calc_theta(word.category, word.subcategory)
    r = calc_relation(word.syntax, word.term_freq)
    z = calc_attribute(word.context, word.sentiment)
    
    # 文脈補正
    Δr, Δz, Δθ = context_adjust(word, prev_word)
    
    # 合成
    θ_final = θ + Δθ
    r_final = r + Δr
    z_final = z + Δz
    
    coordinates.append((θ_final, r_final, z_final))

# 折れ線グラフとしてプロット
plot_cylindrical_path(coordinates)
________________________________________
【表7】評価項目と調査手法
項目	データ源	手法	概算コスト
公共度	国語辞典／新聞／SNS	頻度統計＋分布正規化	低
専門性	技術論文・特許	用語頻度の逆数＋TF-IDF	中
感情強度	感情辞書（日本語評価極性辞典等）	極性平均値＋確信度	低
比喩・皮肉	比喩検出モデル（transformer）	相関ベクトル＋距離変化	高
対義方向	WordNet等	上位下位／反意語リンク解析	中
文体分類	BERT文体識別器	俗語〜公式語の推定	中
________________________________________
【図1】意味折れ線グラフの概念図（例）
z↑    * (高次専門語・公式文体)
 |    /
 |   /
 |  * (中位専門語)
 | /   
 |* (日常語・感情強)
 +--------------------→ r (専門性)
        θ（分野角度方向）
________________________________________
 
________________________________________
LCB-Ext：拡張ベクタ仕様書（Ver.0.1 初期版）
1. 目的（Purpose）
拡張ベクタ（Extended Axes）は、
意味座標3軸・発音座標3軸では捉えきれない、感性・社会言語学・談話的特徴を表現するための可変パラメータ群。
•	言語横断的に使えるもの
•	言語ごとに追加できるもの
•	文脈評価（感情分析、敬語、緊迫性など）にも利用可能
________________________________________
📐 2. 基本構造（Structure）
拡張ベクタは dictベースの可変長 とし、軸は JSON 形式で定義する。
"extended_axes": {
  "axis_name": {
    "range": [min_value, max_value],
    "default": 0.0,
    "description": "explanation",
    "category": "emotion | sociolinguistic | modality | discourse | culture"
  }
}
すべての軸は 連続値（float） として扱う。
（ただし 0/1 の二値を float で表現してもよい）
________________________________________
🌈 3. 初期バージョンの標準軸（LCB-Ext v0.1）
初期バージョンでは以下の 5軸 を標準として取り込む。
(1) Politeness（丁寧さ）
•	category: sociolinguistic
•	range: 0.0 = くだけた / 1.0 = 丁寧
日本語では重要度が極めて高い軸。
________________________________________
(2) Formality（形式性）
•	category: sociolinguistic
•	range: 0.0 = 口語 / 1.0 = 書き言葉
________________________________________
(3) Urgency（切迫性）
•	category: discourse
•	range: 0.0 = 平静 / 1.0 = 切迫・急務
あなたが提案した「焦り / 必死さ」を反映する軸。
単語の意味/文体に現れるケースが多い（例：「急げ」「早く」「至急」など）。
※文脈の強調（!!! や 重複）とは別に、
語彙レベルでも切迫性は存在するため、軸として設定する価値がある。
________________________________________
(4) Emphasis（強調度）
•	category: discourse
•	range: 0.0 = 通常 / 1.0 = 強調語
例：
•	絶対に
•	ほんとうに
•	まったく
•	非常に
________________________________________
(5) Confidence（確信度）
•	category: modality
•	range: 0.0 = 推量 / 1.0 = 確信・断定
例：
•	「かもしれない」→ 0.1
•	「と思われる」→ 0.4
•	「である」「確実」→ 1.0
________________________________________
🧩 4. 軸の増減方法（可変式デザイン）
軸は JSON で自由に追加できる：
"extended_axes": {
  "politeness": {...},
  "urgency": {...},
  "emotion_joy": {...},
  "emotion_anger": {...}
}
追加可能なカテゴリ：
•	emotion系
joy / anger / sadness / fear / surprise
•	attitude系
positive / negative / hostile / cooperative
•	modality系
possibility / necessity / obligation
•	culture系
和風/漢語/外来語系統など
________________________________________
⚙️ 5. 評価関数の仕様（compute_extended_axes）
Python モジュール側での必須仕様：
def compute_extended_axes(word, reading=None, pos=None, context=None):
    """
    Returns dict {axis_name: float}

    Required:
        - axis names must match extended_axes.json
        - values must be clipped to axis range
        - context can be None (単語単独でも動作)
    """
単語レベルで判定
•	語彙の意味：辞書・WordNet・LCB意味ベクトル
•	形態：語尾・用言の活用・敬語接辞
•	fastTextによる類似語クラスタ
•	ConceptNetの関係性
文脈を併用する場合
•	context は optional
•	将来的には文章全体のスコアリングにも使用可能
________________________________________
🧮 6. ベクトルへのエンコード
データ保存時は順番を固定：
[politeness, formality, urgency, emphasis, confidence]
可変対応のため、
軸名→インデックスのマッピング表（JSON）も作ることを推奨：
"extended_axis_order": ["politeness", "formality", "urgency", "emphasis", "confidence"]
________________________________________

 
資料　LCB 軸定義 JSON：初期バージョン

•	意味座標 3軸
•	発音座標 3軸
•	拡張ベクタ（可変式）
•	WordNet（統計）
•	将来の追加を前提とした柔軟構造
{
  "lcb_axes": {
    "version": "0.1",
    "description": "LCB coordinate system (initial minimal version)",
    
    "semantic_axes": {
      "concreteness": {
        "range": [0.0, 1.0],
        "description": "抽象 (0.0) ↔ 具体 (1.0)"
      },
      "valence": {
        "range": [-1.0, 1.0],
        "description": "不快 (-1.0) ↔ 快 (+1.0)"
      },
      "agency": {
        "range": [0.0, 1.0],
        "description": "非能動 (0.0) ↔ 能動 (1.0)"
      }
    },

    "phonetic_axes": {
      "openness": {
        "range": [0.0, 1.0],
        "description": "母音開度：閉 (0.0) ↔ 開 (1.0)"
      },
      "sharpness": {
        "range": [0.0, 1.0],
        "description": "破裂音・摩擦音による鋭さ"
      },
      "rhythm": {
        "range": [0.0, 1.0],
        "description": "テンポ感・拍の強弱"
      }
    },

    "extended_axes": {
      "description": "言語文化依存の追加可能パラメータ（可変 dict）",
      "default_axes": {
        "politeness": {
          "range": [0.0, 1.0],
          "description": "丁寧さ・尊敬度"
        },
        "urgency": {
          "range": [0.0, 1.0],
          "description": "切迫性・急ぎの度合い"
        },
        "confidence": {
          "range": [0.0, 1.0],
          "description": "確信度・断定の強さ"
        },
        "emphasis": {
          "range": [0.0, 1.0],
          "description": "強調の度合い"
        },
        "formality": {
          "range": [0.0, 1.0],
          "description": "形式性・書き言葉度"
        }
      }
    },

    "wordnet_features": {
      "sense_count": {
        "description": "シノセット数"
      },
      "hypernym_depth": {
        "description": "上位語階層の深さ（語義構造の抽象度）"
      },
      "polysemy_score": {
        "description": "多義性（複数意味の持ちやすさ）"
      }
    }
  }
}
 
追加資料　wordnet DB情報

(venv_wikidict) E:\LCB>tools\check_jawordnet.py
Tables: ['pos_def', 'link_def', 'synset_def', 'synset_ex', 'synset', 'synlink', 'ancestor', 'sense', 'word', 'variant', 'xlink']

--- Table: pos_def ---
('a', 'eng', 'adjective')
('r', 'eng', 'adverb')
('n', 'eng', 'noun')
('v', 'eng', 'verb')
('a', 'jpn', '形容詞')

--- Table: link_def ---
('also', 'eng', 'See also')
('syns', 'eng', 'Synonyms')
('hype', 'eng', 'Hypernyms')
('inst', 'eng', 'Instances')
('hypo', 'eng', 'Hyponym')

--- Table: synset_def ---
('07125096-n', 'eng', 'profane or obscene expression usually of surprise or anger; "expletives were deleted"', '0')
('07126228-n', 'eng', 'a word or phrase conveying no independent meaning but added to fill out a sentence or metrical line', '0')
('14123044-n', 'eng', 'an acute and highly contagious viral disease marked by distinct red spots followed by a rash; occurs primarily in children', '0')
('08030185-n', 'eng', 'a Nicaraguan counterrevolutionary guerrilla force from 1979 to 1990; it opposed a left-wing government, with support from the United States', '0')
('09902017-n', 'eng', 'a man who raises (or tends) cattle', '0')

--- Table: synset_ex ---
('01785341-a', 'eng', 'grim determination', '0')
('01785341-a', 'jpn', '断固たる決心', '0')
('01785341-a', 'eng', 'grim necessity', '1')
('01785341-a', 'jpn', '厳しい必要性', '1')
('01785341-a', 'eng', "Russia's final hour, it seemed, approached with inexorable certainty", '2')

--- Table: synset ---
('07125096-n', 'n', 'expletive', 'eng30')
('07126228-n', 'n', 'expletive', 'eng30')
('14123044-n', 'n', 'measles', 'eng30')
('08030185-n', 'n', 'contras', 'eng30')
('09902017-n', 'n', 'beef_man', 'eng30')

--- Table: synlink ---
('07125096-n', '07128527-n', 'hype', 'eng30')
('07126228-n', '07109847-n', 'hype', 'eng30')
('14123044-n', '14122235-n', 'hype', 'eng30')
('14123044-n', '14123259-n', 'hypo', 'eng30')
('08030185-n', '08197895-n', 'inst', 'eng30')

--- Table: ancestor ---
('11820323-n', '11573660-n', 1)
('11820323-n', '11567411-n', 2)
('11820323-n', '08108972-n', 3)
('11820323-n', '07992450-n', 4)
('11820323-n', '07941170-n', 5)

--- Table: sense ---
('07125096-n', 1, 'eng', '0', 1, 1, 'eng-30')
('07126228-n', 1, 'eng', '0', 2, 0, 'eng-30')
('14123044-n', 2, 'eng', '0', 1, 0, 'eng-30')
('08030185-n', 3, 'eng', '0', 1, 0, 'eng-30')
('09902017-n', 4, 'eng', '0', 1, 1, 'eng-30')

--- Table: word ---
(1, 'eng', 'expletive', None, 'n')
(2, 'eng', 'measles', None, 'n')
(3, 'eng', 'contras', None, 'n')
(4, 'eng', 'beef_man', None, 'n')
(5, 'eng', 'dwelling', None, 'n')

--- Table: variant ---

--- Table: xlink ---
('00001740-a', 'sumo', 'capability', '=', None)
('00002098-a', 'sumo', 'capability', '⊂', None)
('00002312-a', 'sumo', 'PositionalAttribute', '⊂', None)
('00002527-a', 'sumo', 'PositionalAttribute', '⊂', None)
('00002956-a', 'sumo', 'BiologicalAttribute', '⊂', None)
